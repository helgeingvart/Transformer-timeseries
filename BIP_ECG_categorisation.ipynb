{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Utilizing transformers for categorization of ECG timeseries\n",
    "\n",
    "This project builds on the work of various ML researchers, mainly Kevin Ko who wrote the original Transformer code\n",
    "for text processing, and Mahmut Gokmen who adapted it to time series classification. For more information, see these links:\n",
    "\n",
    "Kevin Ko's work: https://github.com/hyunwoongko/transformer\n",
    "\n",
    "Mahumd Gokmens adaption: https://github.com/mselmangokmen/TimeSeriesProject/\n",
    "\n",
    "This code requires pytorch"
   ],
   "id": "b0030b68590aad0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First step: Make sure we have all the necessary imports",
   "id": "a72910e1d2978dd3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-08T09:06:44.781659Z",
     "start_time": "2024-09-08T09:06:41.518574Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we use the traditional sinusoidal positional encoder from the \"Attention is all you need\" paper",
   "id": "72635c4400d77f9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T09:06:54.302434Z",
     "start_time": "2024-09-08T09:06:54.295516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dropout: float=0.1,\n",
    "            max_seq_len: int=5000,\n",
    "            d_model: int=512,\n",
    "            batch_first: bool=False    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.batch_first = batch_first\n",
    "        self.x_dim = 1 if batch_first else 0\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_seq_len, 1, d_model)\n",
    "\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(self.x_dim)]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ],
   "id": "af79f6d5327e3f68",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, the multihead-attention mechanmism",
   "id": "a01e4aac402f1ea9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T09:16:11.306661Z",
     "start_time": "2024-09-08T09:16:11.295500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from models.layers.scale_dot_product_attention import ScaleDotProductAttention\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_head, details):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.attention = ScaleDotProductAttention( details=details)\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_concat = nn.Linear(d_model, d_model)\n",
    "        self.details = details\n",
    "\n",
    "    def forward(self, q, k, v ):\n",
    "        # 1. dot product with weight matrices\n",
    "\n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "\n",
    "        if self.details: print('in Multi Head Attention Q,K,V: '+ str(q.size()))\n",
    "        # 2. split tensor by number of heads\n",
    "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
    "\n",
    "        if self.details: print('in splitted Multi Head Attention Q,K,V: '+ str(q.size()))\n",
    "        # 3. do scale dot product to compute similarity\n",
    "        out, attention = self.attention(q, k, v )\n",
    "\n",
    "        if self.details: print('in Multi Head Attention, score value size: '+ str(out.size()))\n",
    "        # 4. concat and pass to linear layer\n",
    "        out = self.concat(out)\n",
    "        out = self.w_concat(out)\n",
    "\n",
    "        # 5. visualize attention map\n",
    "        # TODO : we should implement visualization\n",
    "\n",
    "        if self.details: print('in Multi Head Attention, score value size after concat : '+ str(out.size()))\n",
    "        return out\n",
    "\n",
    "    def split(self, tensor):\n",
    "        \"\"\"\n",
    "        split tensor by number of head\n",
    "\n",
    "        :param tensor: [batch_size, length, d_model]\n",
    "        :return: [batch_size, head, length, d_tensor]\n",
    "        \"\"\"\n",
    "        batch_size, length, d_model = tensor.size()\n",
    "        d_tensor = d_model // self.n_head\n",
    "        tensor = tensor.view(batch_size, length, self.n_head, d_tensor).transpose(1, 2)\n",
    "        # it is similar with group convolution (split by number of heads)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def concat(self, tensor):\n",
    "        \"\"\"\n",
    "        inverse function of self.split(tensor : torch.Tensor)\n",
    "\n",
    "        :param tensor: [batch_size, head, length, d_tensor]\n",
    "        :return: [batch_size, length, d_model]\n",
    "        \"\"\"\n",
    "        batch_size, head, length, d_tensor = tensor.size()\n",
    "        d_model = head * d_tensor\n",
    "\n",
    "        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, d_model)\n",
    "        return tensor"
   ],
   "id": "3b2006c8216008b2",
   "outputs": [],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
